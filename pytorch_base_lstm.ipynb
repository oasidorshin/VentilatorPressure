{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b705c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from data import preprocessing, postprocessing\n",
    "from modelling import LSTMModel, train_epoch, valid_epoch, L1Loss_masked\n",
    "from func import get_timestamp\n",
    "\n",
    "import timeit, copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10eaba2",
   "metadata": {},
   "source": [
    "## Working with data and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kwargs = {'u_in_cumsum': True,\n",
    "          'u_in_lag12': True,\n",
    "          'u_in_lag_back12': True,\n",
    "          'u_in_diff12': True,\n",
    "          'area_true': False,\n",
    "          'u_in_mean': False,\n",
    "          'u_in_last': False,\n",
    "          'scaler': RobustScaler()}\n",
    "train, test, features = preprocessing(train, test, **data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97beba3d-7ae8-4058-b80a-e2838c5ca259",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df47beb-5969-4115-b621-fe7169d21254",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['pressure']\n",
    "train.drop(columns = ['id', 'breath_id', 'pressure'], inplace = True)\n",
    "test.drop(columns = ['id', 'breath_id'], inplace = True)\n",
    "input_size = train.shape[1]\n",
    "features, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset\n",
    "train = torch.tensor(train.to_numpy()).reshape(-1,80, input_size).float()\n",
    "test = torch.tensor(test.to_numpy()).reshape(-1,80, input_size).float()\n",
    "target = torch.tensor(target.to_numpy()).reshape(-1,80,1).float()\n",
    "\n",
    "train_dataset = TensorDataset(train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2fed3-f618-4867-8a15-a8d4174052fe",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c629959-411f-493d-9b30-5a69b87cddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    hidden_dim = 128\n",
    "    num_layers = 4\n",
    "    lr = 1.42e-03\n",
    "    \n",
    "    batch_size = 256\n",
    "    num_workers = 4\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    num_epochs = 300\n",
    "    k = 5\n",
    "    infer_k = 5\n",
    "      \n",
    "cfg = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb34bbb2-550e-4fb6-93fd-35106d02d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = False\n",
    "training = True\n",
    "inference = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2fafb9-972f-419a-9580-f276c01362ad",
   "metadata": {},
   "source": [
    "## LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7fac05-542b-4b38-a809-1a665693b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr_finder:\n",
    "    model = model = LSTMModel(input_size,128,4)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.000001)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, num_workers=4)\n",
    "    lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "    lr_finder.range_test(train_loader, end_lr=100, num_iter=100)\n",
    "    lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "    lr_finder.reset() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ac06b-ad1c-4ce4-afb0-333e9ade2fb7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6764e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=cfg.k,shuffle=True,random_state=42)\n",
    "\n",
    "opt_criterion = nn.L1Loss()\n",
    "val_criterion = L1Loss_masked()\n",
    "\n",
    "device = cfg.device\n",
    "\n",
    "if training:\n",
    "    timestamp = get_timestamp()\n",
    "    \n",
    "    val_losses = []\n",
    "    for fold, (train_idx,val_idx) in enumerate(kf.split(train)):\n",
    "        print(f\"Fold {fold + 1}\", \"\\n\")\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, sampler=train_sampler, num_workers = cfg.num_workers)\n",
    "        val_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, sampler=val_sampler, num_workers = cfg.num_workers)\n",
    "\n",
    "        model = LSTMModel(input_size,cfg.hidden_dim,cfg.num_layers)\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "        \n",
    "        best_val_loss = 1000\n",
    "        best_weights = model.state_dict()\n",
    "        restart = 15\n",
    "        \n",
    "        for epoch in range(cfg.num_epochs):\n",
    "            start_time = timeit.default_timer()\n",
    "            train_loss = train_epoch(model,device,train_loader,opt_criterion,optimizer)\n",
    "            val_loss = valid_epoch(model,device,val_loader,val_criterion)\n",
    "            end_time = timeit.default_timer()\n",
    "            \n",
    "            total = end_time - start_time\n",
    "\n",
    "            train_loss = np.mean(np.array(train_loss))\n",
    "            val_loss = np.mean(np.array(val_loss))\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_weights = copy.copy(model.state_dict())\n",
    "            \n",
    "            print(f\"Epoch: {epoch + 1} | T loss: {train_loss:.4f} V loss: {val_loss:.4f} Best: {best_val_loss:.4f} Time: {total:.4f}\")\n",
    "            \n",
    "            if train_loss > restart or val_loss > restart:\n",
    "                # For some reason sometimes it bugs out and gets to the point with 17 mae and no exit\n",
    "                # Just restart\n",
    "                print(\"Restarting...\")\n",
    "                train_sampler = SubsetRandomSampler(train_idx)\n",
    "                val_sampler = SubsetRandomSampler(val_idx)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, sampler=train_sampler, num_workers = cfg.num_workers)\n",
    "                val_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, sampler=val_sampler, num_workers = cfg.num_workers)\n",
    "              \n",
    "                model = LSTMModel(input_size,cfg.hidden_dim,cfg.num_layers)\n",
    "                model.to(device)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "              \n",
    "                best_weights = model.state_dict() \n",
    "            \n",
    "        val_losses.append(best_val_loss)    \n",
    "        torch.save(best_weights, f\"models/fold_{fold}_{timestamp}.pth\")\n",
    "        break\n",
    "        \n",
    "    print(\"Avg final val loss\", np.mean(val_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72af70c-a7a9-421a-a61d-859004c744f2",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22944c57-b243-4858-b2e9-9492ec66cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference:\n",
    "    timestamp = get_timestamp()\n",
    "    df = pd.read_csv('data/sample_submission.csv')\n",
    "    \n",
    "    test_target = torch.zeros(test.shape[0],80,1).float()\n",
    "    test_dataset = TensorDataset(test, test_target)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, num_workers = cfg.num_workers)\n",
    "    \n",
    "    for fold in range(cfg.k):\n",
    "        model = LSTMModel(input_size,cfg.hidden_dim,cfg.num_layers)\n",
    "        model.to(device)\n",
    "        filename = f'models/fold_{fold}_2021-10-14-10-18.pth'\n",
    "        model.load_state_dict(torch.load(filename, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        y_preds = []\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(x).squeeze()\n",
    "\n",
    "            y_preds.append(y_pred.cpu().numpy())\n",
    "\n",
    "        y_preds = np.concatenate(y_preds, axis=0).ravel()\n",
    "        df[fold] = y_preds\n",
    "\n",
    "    submission = postprocessing(df, cfg.k)\n",
    "    submission.to_csv(f'submissions/{timestamp}.csv', index = False)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6ee99-982f-4e51-95c7-cf95650bd59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
